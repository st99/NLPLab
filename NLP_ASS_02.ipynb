{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_ASS_02.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"7AwLOcyKQSE1"},"source":["Importing required packages"]},{"cell_type":"code","metadata":{"id":"7A5a6DwSDBPR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607505045647,"user_tz":-330,"elapsed":7174,"user":{"displayName":"UI17CO25_Shubham Tayal","photoUrl":"","userId":"13395258198696622107"}},"outputId":"ceb84b3a-6793-4e81-e59a-fc22f3d332a0"},"source":["!pip install nltk\n","import nltk\n","import string\n","import re\n","nltk.download('punkt')\n","nltk.download('wordnet')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"Or_-slcwDmLd","executionInfo":{"status":"ok","timestamp":1607505045652,"user_tz":-330,"elapsed":7163,"user":{"displayName":"UI17CO25_Shubham Tayal","photoUrl":"","userId":"13395258198696622107"}}},"source":["from nltk.tokenize import sent_tokenize\n","from nltk.tokenize import word_tokenize"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g5XlZcdPQeBF"},"source":["Initialising the paragraph"]},{"cell_type":"code","metadata":{"id":"RgP3mk4KQxK8","executionInfo":{"status":"ok","timestamp":1607505046139,"user_tz":-330,"elapsed":7637,"user":{"displayName":"UI17CO25_Shubham Tayal","photoUrl":"","userId":"13395258198696622107"}}},"source":["paragraph = \"helloooooo, i'm currently not studying in Surat.\\nToday's my bday.\""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"2v9yq7VVOQsZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607505046142,"user_tz":-330,"elapsed":7615,"user":{"displayName":"UI17CO25_Shubham Tayal","photoUrl":"","userId":"13395258198696622107"}},"outputId":"da7c7fa0-d831-43e1-fcee-b547657ca0a3"},"source":["R_patterns = [\n","   (r'won\\'t', 'will not'),\n","   (r'can\\'t', 'cannot'),\n","   (r'i\\'m', 'i am'),\n","   (r'(\\w+)\\'ll', '\\g<1> will'),\n","   (r'(\\w+)n\\'t', '\\g<1> not'),\n","   (r'(\\w+)\\'ve', '\\g<1> have'),\n","   (r'(\\w+)\\'s', '\\g<1> is'),\n","   (r'(\\w+)\\'re', '\\g<1> are'),\n","]\n","class REReplacer(object):\n","  def __init__(self, patterns=R_patterns):\n","    self.patterns = [(re.compile(regex), repl) for (regex, repl) in patterns]\n","  def replace(self, text):\n","    s = text\n","    for (pattern, repl) in self.patterns:\n","      s = re.sub(pattern, repl, s)\n","    return s\n","rep_word = REReplacer()\n","rep_paragraph = rep_word.replace(paragraph)\n","print(rep_paragraph)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["helloooooo, i am currently not studying in Surat.\n","Today is my bday.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Os8_EOhgQkpI"},"source":["Tokenizing the paragraph"]},{"cell_type":"code","metadata":{"id":"vYhI0-G-EG3b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607505046145,"user_tz":-330,"elapsed":7598,"user":{"displayName":"UI17CO25_Shubham Tayal","photoUrl":"","userId":"13395258198696622107"}},"outputId":"38078916-c302-4369-d258-114078f66f3b"},"source":["words = word_tokenize(rep_paragraph)\n","print(words)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["['helloooooo', ',', 'i', 'am', 'currently', 'not', 'studying', 'in', 'Surat', '.', 'Today', 'is', 'my', 'bday', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gJaeV-jHQLyI"},"source":["Removing Punctuations"]},{"cell_type":"code","metadata":{"id":"XSS8l81WO3V_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607505046147,"user_tz":-330,"elapsed":7580,"user":{"displayName":"UI17CO25_Shubham Tayal","photoUrl":"","userId":"13395258198696622107"}},"outputId":"4afa0ab4-3a45-4bc7-cfe2-3392805744f3"},"source":["only_words = [w for w in words if not w in string.punctuation]\n","print(only_words)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["['helloooooo', 'i', 'am', 'currently', 'not', 'studying', 'in', 'Surat', 'Today', 'is', 'my', 'bday']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DSaUsN8qwBAm"},"source":["Removing repeated letters in words"]},{"cell_type":"code","metadata":{"id":"p_szvaQbSkfn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607505047827,"user_tz":-330,"elapsed":9242,"user":{"displayName":"UI17CO25_Shubham Tayal","photoUrl":"","userId":"13395258198696622107"}},"outputId":"05d6db5d-20d9-4e30-a566-6ddfd543ebd8"},"source":["from nltk.corpus import wordnet\n","\n","class Rep_word_removal(object):\n","  def __init__(self):\n","    self.repeat_regexp = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n","    self.repl = r'\\1\\2\\3'\n","  def replace(self, word):\n","    if wordnet.synsets(word):\n","      return word\n","    replace_word = self.repeat_regexp.sub(self.repl, word)\n","    if replace_word != word:\n","      return self.replace(replace_word)\n","    else:\n","      return replace_word\n","rep_words = []\n","rep_word = Rep_word_removal()\n","for i in only_words:\n","  rep_words.append(rep_word.replace(i))\n","print(rep_words)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["['hello', 'i', 'am', 'currently', 'not', 'studying', 'in', 'Surat', 'Today', 'is', 'my', 'bday']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UpqRYPccv9mw"},"source":["Importing CSVs"]},{"cell_type":"code","metadata":{"id":"5J231Jsqj1id","executionInfo":{"status":"ok","timestamp":1607505047830,"user_tz":-330,"elapsed":9237,"user":{"displayName":"UI17CO25_Shubham Tayal","photoUrl":"","userId":"13395258198696622107"}}},"source":["import csv\n","import pandas as pd\n","import requests"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"6eEbTiVnjWD_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607505593974,"user_tz":-330,"elapsed":1072,"user":{"displayName":"UI17CO25_Shubham Tayal","photoUrl":"","userId":"13395258198696622107"}},"outputId":"629cd74e-a62b-4074-f36d-bdbce3962d14"},"source":["from google.colab import files\n","from google.colab import drive\n","drive.mount('/content/drive')\n","filesyn = pd.read_csv('/content/drive/My Drive/synonyms.csv', header=None)\n","fileant = pd.read_csv('/content/drive/My Drive/antonyms.csv', header=None)\n","print('\\nSynonyms')\n","print(filesyn)\n","print('\\nAntonyms')\n","print(fileant)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","           0          1\n","0       bday   birthday\n","1      hello         hi\n","2  currently  presently\n","\n","          0         1\n","0  studying  sleeping\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CYmMNl90v6ir"},"source":["Replacing Synonyms"]},{"cell_type":"code","metadata":{"id":"zg7JGQ2BW5s2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607505232881,"user_tz":-330,"elapsed":1160,"user":{"displayName":"UI17CO25_Shubham Tayal","photoUrl":"","userId":"13395258198696622107"}},"outputId":"9b9438cd-2f9d-4418-c9b4-cecddace7456"},"source":["class csv_synonym_replacer(object):\n","  def __init__(self, fname):\n","    self.word_map = {}\n","    for i in range(len(fname)):\n","      self.word_map[fname.iloc[i,0]] = fname.iloc[i,1]\n","  \n","  def replace(self, word):\n","        return self.word_map.get(word, word)\n","syn_replacer = csv_synonym_replacer(filesyn)\n","syn_words = [];\n","for i in rep_words:\n","  syn_words.append(syn_replacer.replace(i))\n","print(syn_words)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["['hi', 'i', 'am', 'presently', 'not', 'studying', 'in', 'Surat', 'Today', 'is', 'my', 'birthday']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lpcFbnevv1PP"},"source":["Replacing Antonyms"]},{"cell_type":"code","metadata":{"id":"Y4D3m75optcn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607505711206,"user_tz":-330,"elapsed":1268,"user":{"displayName":"UI17CO25_Shubham Tayal","photoUrl":"","userId":"13395258198696622107"}},"outputId":"7841cd69-34f2-4a79-fc61-82a6a1dfc36f"},"source":["class csv_antonym_replacer(object):\n","\n","  def __init__(self, fname):\n","    self.word_map = {}\n","    for i in range(len(fname)):\n","      self.word_map[fname.iloc[i,0]] = fname.iloc[i,1]\n","  \n","  def replace(self, word):\n","        return self.word_map.get(word, word)\n","  \n","  def replace_negations(self, sent):\n","    i, l = 0, len(sent)\n","    words = []\n","    \n","    while i < l:\n","        word = sent[i]\n","        \n","        if word == 'not' and i+1 < l:\n","          ant = self.replace(sent[i+1])\n","          \n","          if ant:\n","              words.append(ant)\n","              i += 2\n","              continue\n","        \n","        words.append(word)\n","        i += 1\n","    \n","    return words\n","\n","ant_replacer = csv_antonym_replacer(fileant)\n","ant_words = [];\n","for i in rep_words:\n","  ant_words.append(ant_replacer.replace_negations(i))\n","ant_words = ant_replacer.replace_negations(rep_words)\n","print(ant_words)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["['hello', 'i', 'am', 'currently', 'sleeping', 'in', 'Surat', 'Today', 'is', 'my', 'bday']\n"],"name":"stdout"}]}]}